# 项目名称：深圳 OD 流动网络的 DySAT 动态嵌入与演化社区检测

## 研究目标
利用 **DySAT（Dynamic Self-Attention Network）** 对 **深圳 20240513–20240519 一周内逐小时 OD 流动网络**进行动态图嵌入，并结合 **EvoLouvain 动态社区检测**，揭示：  
1. **高阶时间依赖**（跨快照的长期模式）  
2. **跨空间功能相似性**（地理位置分散但功能相似的格网）  
 

---

## 数据说明
输入 CSV 格式：
date_dt,time_,o_grid,d_grid,cu_freq,total_freq
20240519,0,58617,66204,1,2
20240519,0,63604,96877,1,3
20240519,0,84360,92671,1,10

yaml
复制代码
- **date_dt**：日期（YYYYMMDD）  
- **time_**：小时（0–23）  
- **o_grid, d_grid**：起点/终点格网 ID（节点数约 8000–20000）  
- **total_freq**：边权重  

---

## 步骤流程

阶段一: 数据加载与特征工程
目标: 实现健壮的数据加载器，从原始OD数据中构建时序图，并基于图的统计特性生成节点初始特征。

涉及模块: data/temporal_graph_loader.py, data/graph_statistics.py, data/graph_cache.py, config.py

Prompt:

角色: 数据工程师
任务:

实现图加载器: 在 data/temporal_graph_loader.py 中，创建 TemporalGraphLoader 类。它能根据 config.py 中指定的路径，读取 mobility_edges/ 目录下的逐小时OD数据，并构建一个按时间排序的 networkx 图对象列表。确保所有图快照共享一个统一、完整的节点集。

实现特征计算: 在 data/graph_statistics.py 中，创建 GraphStatistics 类。实现一个核心方法 compute_static_node_features()，该方法接收完整的图序列，计算每个节点在整个观测周期内的聚合统计特征（例如：总流入/流出量、度中心性、工作日/周末流量比率等），并返回一个经过标准化的节点特征矩阵 X。

实现缓存机制: 在 data/graph_cache.py 中，实现 GraphCache 类，用于将加载的图对象和计算的特征矩阵序列化到 cache/ 目录，在后续运行时可直接加载，避免重复计算。

配置化: 在 config.py 中，明确定义数据路径、缓存开关、特征工程相关参数。

阶段二: DySAT模型与训练
目标: 实现DySAT模型及其训练流程，学习并生成高质量的动态节点嵌入。

涉及模块: models/dysat.py, models/dysat_preprocessor.py, models/dysat_trainer.py

Prompt:

角色: 机器学习工程师
任务:

实现模型: 在 models/dysat.py 中，实现 DySAT 模型的核心架构（基于PyTorch），包括结构注意力和时间注意力层。

实现预处理器: 在 models/dysat_preprocessor.py 中，创建 DySATPreprocessor 类。它负责将阶段一的输出（图序列、特征矩阵）转换为 DySAT 模型所需的张量格式。

实现训练器: 在 models/dysat_trainer.py 中，创建 DySATTrainer 类。它应包含：

一个 train() 方法，负责完整的训练循环，并将训练好的模型权重保存到 models/ 目录。

一个 get_embeddings() 方法，加载训练好的模型，对完整的图序列执行一次前向传播，并返回最终的动态嵌入张量 H∈R 
∣V∣×T×D_out
 。

集成到主流程: 在 main_pipeline.py 中，调用上述模块，完成从数据加载到嵌入生成的全过程，并将嵌入结果保存到 outputs/experiment_.../embeddings/ 目录。

阶段三: 两阶段STGMM聚类与模式识别 (核心)
目标: 实现创新的两阶段STGMM算法，先捕捉各节点独特的日节律，再将相似节律的节点聚合为全局动态模式。

涉及模块: analysis/pattern_recognizer.py

Prompt:

角色: 数据科学家
任务:
在 analysis/pattern_recognizer.py 中，创建一个 TwoStagePatternRecognizer 类，用于实现分阶段的时空聚类。

初始化 __init__:

  * 接收来自 `config.py` 的关键超参数：
      * `k_temporal`: 阶段一中，为每个节点拟合GMM时的簇数（代表本地状态数，建议值为3-5）。
      * `k_global_range`: 阶段二中，全局GMM的候选簇数范围（例如 `[4, 5, 6, 7, 8]`）。
主方法 run(H):

  * 接收阶段二输出的动态嵌入张量 `H` (`|V|, T, D_out`)。
  * **第一步**: 调用内部方法 `_extract_rhythm_signatures(H)`，完成阶段一，获得节律签名矩阵 `Φ` (`|V|, D_rhythm`)。
  * **第二步**: 调用内部方法 `_aggregate_global_patterns(Φ)`，完成阶段二，获得全局隶属度矩阵 `U_global` (`|V|, K_global`) 和训练好的全局GMM模型。
  * **第三步**: 调用内部方法 `_reconstruct_temporal_memberships(H, global_gmm)`，根据全局GMM模型，重构出每个节点在每个小时的隶属度，得到最终的时序隶属度张量 `U_final` (`|V|, T, K_global`)。
  * **返回**: `U_final`, `U_global`, 和 `global_gmm` 模型。
内部方法 _extract_rhythm_signatures(H):

  * 遍历 `H` 的 `|V|` 个节点。对每个节点的时序嵌入 `H_v` (`T, D_out`)，拟合一个独立的、小型的 `GaussianMixture` 模型（簇数为 `k_temporal`）。
  * 从拟合好的本地GMM中，提取其参数（`means_`, `covariances_`, `weights_`），并将它们展平、拼接成一个长的“日节律签名向量” `phi_v`。
  * 返回所有节点签名向量组成的矩阵 `Φ`。
内部方法 _aggregate_global_patterns(Φ):

  * 在节律签名矩阵 `Φ` 上拟合一个全局的 `GaussianMixture` 模型。
  * 使用BIC准则，从 `k_global_range` 中自动选择最佳的全局簇数 `K_global`。
  * 用最佳 `K_global` 训练最终的全局GMM模型，并预测每个节点的全局隶属度 `U_global`。
  * 返回 `U_global` 和训练好的 `global_gmm` 模型。
内部方法 _reconstruct_temporal_memberships(H, global_gmm):

  * 这是连接全局模式与瞬时状态的关键一步。
  * 将原始嵌入张量 `H` 变形为 `(|V|*T, D_out)`。
  * 使用阶段二训练好的 `global_gmm` 模型，对这个变形后的矩阵调用 `predict_proba` 方法。
  * 这将计算出每个节点在每个小时的嵌入，分别属于 `K_global` 个全局模式的概率。
  * 将结果重新变形为 `(|V|, T, K_global)`，得到最终的时序隶属度张量 `U_final`。
阶段四: 模式分析与解读
目标: 对识别出的全局模式进行量化分析，赋予其业务含义。

涉及模块: analysis/report_generator.py

Prompt:

角色: 城市科学分析师
任务:
在 analysis/report_generator.py 中，创建 ReportGenerator 类。此类接收阶段三的输出（U_final, U_global）和原始OD数据，进行深度分析。

实现 generate_pattern_profiles(U_final, od_data):

对于 K_global 个全局模式中的每一个，使用 U_final 作为权重，对所有节点的流入/流出量进行加权平均，计算出该模式典型的24小时流量特征曲线。根据曲线形态（如双高峰、夜间峰等）为模式命名。

实现 calculate_tie_stability(U_final):

基于时序隶属度张量 U_final，计算每个节点的**流动模式稳定性（TIE）**指标，衡量其一天内模式切换的剧烈程度。

实现 analyze_global_pattern_distribution(U_global):

基于全局隶属度矩阵 U_global，统计每个全局模式主导的节点数量和比例，生成一个高层级的城市模式构成总结。

将所有分析结果（JSON, CSV）输出到 outputs/experiment_.../report/ 目录。

阶段五: 结果可视化
目标: 将分析结果以直观的图表和地图形式呈现，形成有说服力的可视化报告。

涉及模块: visualization/geographic_visualizer.py, visualization/cluster_visualizer.py

Prompt:

角色: 数据可视化专家
任务:

实现地理可视化: 在 visualization/geographic_visualizer.py 中，创建 GeographicVisualizer 类，该类结合地理元数据进行绘图：

plot_global_dominant_pattern_map(U_global): 绘制一张全局主导模式地图，展示每个区域的总体模式归属，这是对城市结构的核心划分。

plot_hourly_dominant_pattern_map(U_final, hour): 绘制特定小时的瞬时主导模式地图，展示城市在一天内的动态变化。

plot_metric_map(tie_scores): 绘制TIE等指标的空间热力图。

实现统计可视化: 在 visualization/cluster_visualizer.py 中，创建 ClusterVisualizer 类：

plot_pattern_signature_curves(): 绘制由 ReportGenerator 生成的、每个全局模式的流量特征曲线。

plot_global_distribution_pie(): 绘制各全局模式占比的饼图或条形图。

所有图表应保存到 outputs/experiment_.../figures/ 目录。